"""
Analysis Controller - Professional Options Calculator Pro
Handles all analysis business logic and coordinates between services
"""

import logging
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass

from PySide6.QtCore import QObject, Signal, QTimer

from services.market_data import MarketDataService
from services.ml_service import MLService
from services.options_service import OptionsService
from services.volatility_service import VolatilityService
from models.analysis_result import AnalysisResult, ConfidenceScore, RiskMetrics
from models.option_data import OptionChain, OptionContract
from utils.thread_manager import ThreadManager, TaskPriority
from utils.monte_carlo import MonteCarloEngine
from utils.greeks_calculator import GreeksCalculator
from utils.config_manager import ConfigManager


@dataclass
class AnalysisRequest:
    """Analysis request container"""
    symbol: str
    contracts: int = 1
    debit_override: Optional[float] = None
    parameters: Dict[str, Any] = None
    request_id: str = ""
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.parameters is None:
            self.parameters = {}
        if self.timestamp is None:
            self.timestamp = datetime.now()
        if not self.request_id:
            self.request_id = f"{self.symbol}_{int(self.timestamp.timestamp())}"


class AnalysisController(QObject):
    """
    Professional analysis controller that orchestrates the entire analysis process
    """
    
    # Signals for UI communication
    analysis_started = Signal(str)  # symbol
    analysis_progress = Signal(str, int, str)  # symbol, progress, status
    analysis_completed = Signal(str, object)  # symbol, AnalysisResult
    analysis_error = Signal(str, str)  # symbol, error_message
    batch_progress = Signal(int, int, str)  # completed, total, current_symbol
    
    def __init__(self, market_data_service: MarketDataService, 
        self.config_manager = config_manager                 ml_service: MLService, thread_manager: ThreadManager, parent=None):
        super().__init__(parent)
        
        self.logger = logging.getLogger(__name__)
        self.config_manager = ConfigManager()
        
        # Services
        self.market_data_service = market_data_service
        self.ml_service = ml_service
        self.thread_manager = thread_manager
        
        # Additional services
        self.options_service = OptionsService(market_data_service, market_data_service)
        self.volatility_service = VolatilityService(config_manager, market_data_service)
        
        # Analysis engines
        self.monte_carlo_engine = MonteCarloEngine()
        self.greeks_calculator = GreeksCalculator()
        
        # Active analysis tracking
        self.active_analyses: Dict[str, AnalysisRequest] = {}
        self.analysis_cache: Dict[str, AnalysisResult] = {}
        
        # Performance monitoring
        self.analysis_stats = {
            'total_analyses': 0,
            'successful_analyses': 0,
            'failed_analyses': 0,
            'average_duration': 0.0,
            'cache_hits': 0
        }
        
        # Cache cleanup timer
        self.cache_cleanup_timer = QTimer()
        self.cache_cleanup_timer.timeout.connect(self._cleanup_cache)
        self.cache_cleanup_timer.start(300000)  # 5 minutes
        
        self.logger.info("AnalysisController initialized")
    
    def analyze_symbol(self, symbol: str, contracts: int = 1, 
                      debit_override: Optional[float] = None,
                      parameters: Optional[Dict[str, Any]] = None) -> str:
        """
        Start analysis for a single symbol
        
        Args:
            symbol: Stock symbol to analyze
            contracts: Number of contracts
            debit_override: Manual debit override
            parameters: Additional analysis parameters
            
        Returns:
            Request ID for tracking
        """
        try:
            # Validate symbol
            symbol = symbol.strip().upper()
            if not self._validate_symbol(symbol):
                error_msg = f"Invalid symbol: {symbol}"
                self.analysis_error.emit(symbol, error_msg)
                return ""
            
            # Create analysis request
            request = AnalysisRequest(
                symbol=symbol,
                contracts=contracts,
                debit_override=debit_override,
                parameters=parameters or {}
            )
            
            # Check cache first
            cache_key = self._get_cache_key(request)
            if cache_key in self.analysis_cache:
                cached_result = self.analysis_cache[cache_key]
                
                # Check if cache is still valid (15 minutes)
                if (datetime.now() - cached_result.timestamp).total_seconds() < 900:
                    self.logger.debug(f"Using cached result for {symbol}")
                    self.analysis_stats['cache_hits'] += 1
                    
                    # Emit cached result
                    QTimer.singleShot(100, lambda: self.analysis_completed.emit(symbol, cached_result))
                    return request.request_id
            
            # Add to active analyses
            self.active_analyses[request.request_id] = request
            
            # Emit analysis started
            self.analysis_started.emit(symbol)
            
            # Submit analysis task to thread manager
            task_id = self.thread_manager.submit_task(
                function=self._perform_analysis,
                args=(request,),
                priority=TaskPriority.HIGH,
                timeout=120.0,  # 2 minute timeout
                callback=lambda result: self._on_analysis_complete(request.request_id, result),
                error_callback=lambda error: self._on_analysis_error(request.request_id, error)
            )
            
            self.logger.info(f"Started analysis for {symbol} (request: {request.request_id}, task: {task_id})")
            return request.request_id
            
        except Exception as e:
            self.logger.error(f"Error starting analysis for {symbol}: {e}")
            self.analysis_error.emit(symbol, str(e))
            return ""
    
    def analyze_batch(self, symbols: List[str], parameters: Optional[Dict[str, Any]] = None) -> List[str]:
        """
        Start batch analysis for multiple symbols
        
        Args:
            symbols: List of stock symbols
            parameters: Analysis parameters
            
        Returns:
            List of request IDs
        """
        try:
            # Validate symbols
            valid_symbols = [s.strip().upper() for s in symbols if self._validate_symbol(s.strip())]
            
            if not valid_symbols:
                self.analysis_error.emit("BATCH", "No valid symbols provided")
                return []
            
            # Submit individual analyses
            request_ids = []
            for i, symbol in enumerate(valid_symbols):
                try:
                    request_id = self.analyze_symbol(
                        symbol=symbol,
                        contracts=parameters.get('contracts', 1) if parameters else 1,
                        debit_override=parameters.get('debit_override') if parameters else None,
                        parameters=parameters
                    )
                    
                    if request_id:
                        request_ids.append(request_id)
                    
                    # Emit batch progress
                    self.batch_progress.emit(i, len(valid_symbols), symbol)
                    
                except Exception as e:
                    self.logger.error(f"Error starting analysis for {symbol} in batch: {e}")
                    continue
            
            self.logger.info(f"Started batch analysis for {len(request_ids)} symbols")
            return request_ids
            
        except Exception as e:
            self.logger.error(f"Error in batch analysis: {e}")
            self.analysis_error.emit("BATCH", str(e))
            return []
    
    def cancel_analysis(self, request_id: str) -> bool:
        """Cancel an active analysis"""
        try:
            if request_id in self.active_analyses:
                # Remove from active analyses
                request = self.active_analyses.pop(request_id)
                
                # Try to cancel the task (may not be possible if already running)
                self.thread_manager.cancel_task(request_id)
                
                self.logger.info(f"Cancelled analysis for {request.symbol}")
                return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"Error cancelling analysis {request_id}: {e}")
            return False
    
    def get_analysis_status(self, request_id: str) -> Optional[str]:
        """Get status of an analysis request"""
        if request_id in self.active_analyses:
            return "running"
        elif any(request_id in result.request_id for result in self.analysis_cache.values()):
            return "completed"
        else:
            return None
    
    def get_statistics(self) -> Dict[str, Any]:
        """Get analysis controller statistics"""
        stats = self.analysis_stats.copy()
        stats.update({
            'active_analyses': len(self.active_analyses),
            'cached_results': len(self.analysis_cache),
            'thread_manager_stats': self.thread_manager.get_statistics()
        })
        return stats
    
    def _validate_symbol(self, symbol: str) -> bool:
        """Validate stock symbol format"""
        if not symbol or len(symbol) > 10:
            return False
        
        # Basic validation - letters, numbers, dots, hyphens
        import re
        return bool(re.match(r'^[A-Z0-9.\-]+$', symbol))
    
    def _get_cache_key(self, request: AnalysisRequest) -> str:
        """Generate cache key for analysis request"""
        params_str = "_".join(f"{k}:{v}" for k, v in sorted(request.parameters.items()))
        return f"{request.symbol}_{request.contracts}_{request.debit_override}_{hash(params_str)}"
    
    def _perform_analysis(self, request: AnalysisRequest) -> AnalysisResult:
        """
        Perform the actual analysis (runs in background thread)
        
        This is the main analysis engine that orchestrates all calculations
        """
        start_time = datetime.now()
        symbol = request.symbol
        
        try:
            self.logger.info(f"Starting comprehensive analysis for {symbol}")
            
            # Step 1: Get current market data (10% progress)
            self._emit_progress(symbol, 10, "Fetching market data...")
            current_price = self.market_data_service.get_current_price(symbol)
            if not current_price or current_price <= 0:
                raise ValueError(f"Unable to get valid price for {symbol}")
            
            # Step 2: Get historical data (20% progress)
            self._emit_progress(symbol, 20, "Analyzing historical data...")
            historical_data = self.market_data_service.get_historical_data(symbol, period="6mo")
            if historical_data.empty:
                raise ValueError(f"Unable to get historical data for {symbol}")
            
            # Step 3: Get options data (30% progress)
            self._emit_progress(symbol, 30, "Fetching options data...")
            options_data = self.options_service.get_option_chain(symbol)
            if not options_data:
                raise ValueError(f"Unable to get options data for {symbol}")
            
            # Step 4: Calculate volatility metrics (40% progress)
            self._emit_progress(symbol, 40, "Calculating volatility...")
            volatility_metrics = self.volatility_service.calculate_metrics(
                symbol, historical_data, options_data
            )
            
            # Step 5: Get earnings information (50% progress)
            self._emit_progress(symbol, 50, "Checking earnings calendar...")
            earnings_date = self.market_data_service.get_next_earnings(symbol)
            days_to_earnings = self._calculate_days_to_earnings(earnings_date)
            
            # Step 6: Calculate Greeks (60% progress)
            self._emit_progress(symbol, 60, "Calculating Greeks...")
            greeks = self.greeks_calculator.calculate_calendar_spread_greeks(
                current_price, options_data, volatility_metrics
            )
            
            # Step 7: Run Monte Carlo simulation (70% progress)
            self._emit_progress(symbol, 70, "Running Monte Carlo simulation...")
            monte_carlo_params = request.parameters.get('monte_carlo_sims', 10000)
            monte_carlo_result = self.monte_carlo_engine.run_simulation(
                symbol=symbol,
                current_price=current_price,
                historical_data=historical_data,
                volatility_metrics=volatility_metrics,
                simulations=monte_carlo_params,
                days_to_expiration=options_data.get('days_to_expiration', 30)
            )
            
            # Step 8: Calculate confidence score (80% progress)
            self._emit_progress(symbol, 80, "Calculating confidence score...")
            confidence_score = self._calculate_confidence_score(
                symbol, current_price, volatility_metrics, monte_carlo_result,
                days_to_earnings, options_data, greeks
            )
            
            # Step 9: Machine learning prediction (90% progress)
            self._emit_progress(symbol, 90, "Running ML prediction...")
            ml_prediction = None
            if request.parameters.get('use_ml', True):
                try:
                    ml_features = self._prepare_ml_features(
                        symbol, current_price, volatility_metrics, 
                        days_to_earnings, options_data
                    )
                    ml_prediction = self.ml_service.predict(ml_features)
                except Exception as ml_error:
                    self.logger.warning(f"ML prediction failed for {symbol}: {ml_error}")
            
            # Step 10: Calculate risk metrics and final assembly (100% progress)
            self._emit_progress(symbol, 100, "Finalizing analysis...")
            risk_metrics = self._calculate_risk_metrics(
                current_price, options_data, request.contracts,
                request.debit_override, volatility_metrics
            )
            
            # Create analysis result
            analysis_result = AnalysisResult(
                symbol=symbol,
                timestamp=datetime.now(),
                request_id=request.request_id,
                current_price=current_price,
                confidence_score=confidence_score,
                volatility_metrics=volatility_metrics,
                options_data=options_data,
                greeks=greeks,
                monte_carlo_result=monte_carlo_result,
                ml_prediction=ml_prediction,
                risk_metrics=risk_metrics,
                earnings_date=earnings_date,
                days_to_earnings=days_to_earnings,
                analysis_duration=(datetime.now() - start_time).total_seconds()
            )
            
            # Update statistics
            self.analysis_stats['successful_analyses'] += 1
            self.analysis_stats['total_analyses'] += 1
            
            duration = (datetime.now() - start_time).total_seconds()
            total_duration = (self.analysis_stats['average_duration'] * 
                            (self.analysis_stats['successful_analyses'] - 1) + duration)
            self.analysis_stats['average_duration'] = (
                total_duration / self.analysis_stats['successful_analyses']
            )
            
            self.logger.info(f"Completed analysis for {symbol} in {duration:.2f}s")
            return analysis_result
            
        except Exception as e:
            self.analysis_stats['failed_analyses'] += 1
            self.analysis_stats['total_analyses'] += 1
            self.logger.error(f"Analysis failed for {symbol}: {e}")
            raise
    
    def _emit_progress(self, symbol: str, progress: int, status: str):
        """Emit progress signal safely from background thread"""
        # Use QTimer to emit signal in main thread
        QTimer.singleShot(0, lambda: self.analysis_progress.emit(symbol, progress, status))
    
    def _calculate_days_to_earnings(self, earnings_date) -> int:
        """Calculate days until next earnings"""
        if not earnings_date:
            return 90  # Default assumption - quarterly earnings
        
        try:
            if isinstance(earnings_date, str):
                from datetime import datetime
                earnings_date = datetime.strptime(earnings_date, "%Y-%m-%d").date()
            elif hasattr(earnings_date, 'date'):
                earnings_date = earnings_date.date()
            
            today = datetime.now().date()
            return (earnings_date - today).days
            
        except Exception as e:
            self.logger.warning(f"Error calculating days to earnings: {e}")
            return 90
    
    def _calculate_confidence_score(self, symbol: str, current_price: float,
                                  volatility_metrics: dict, monte_carlo_result: dict,
                                  days_to_earnings: int, options_data: dict,
                                  greeks: dict) -> ConfidenceScore:
        """Calculate comprehensive confidence score"""
        try:
            base_score = 50.0
            factors = []
            
            # Volume factor (up to ±15 points)
            avg_volume = options_data.get('average_volume', 0)
            if avg_volume > 1000000:  # $1M+ daily volume
                volume_score = 15.0
                factors.append(('High Volume', volume_score))
            elif avg_volume > 100000:  # $100K+ daily volume
                volume_score = 5.0
                factors.append(('Moderate Volume', volume_score))
            else:
                volume_score = -10.0
                factors.append(('Low Volume', volume_score))
            
            # IV/RV ratio factor (up to ±20 points)
            iv_rv_ratio = volatility_metrics.get('iv_rv_ratio', 1.0)
            if iv_rv_ratio >= 1.5:
                iv_score = 20.0
                factors.append(('High IV/RV Ratio', iv_score))
            elif iv_rv_ratio >= 1.25:
                iv_score = 10.0
                factors.append(('Elevated IV/RV', iv_score))
            elif iv_rv_ratio <= 0.8:
                iv_score = -15.0
                factors.append(('Low IV/RV Ratio', iv_score))
            else:
                iv_score = 0.0
                factors.append(('Normal IV/RV', iv_score))
            
            # Term structure factor (up to ±15 points)
            term_slope = volatility_metrics.get('term_structure_slope', 0.0)
            if term_slope <= -0.005:  # Steep contango
                ts_score = 15.0
                factors.append(('Favorable Term Structure', ts_score))
            elif term_slope <= -0.002:
                ts_score = 8.0
                factors.append(('Mild Contango', ts_score))
            else:
                ts_score = -5.0
                factors.append(('Backwardation', ts_score))
            
            # Monte Carlo probability factor (up to ±15 points)
            prob_1x = monte_carlo_result.get('prob_exceed_1x', 50.0)
            if 40 <= prob_1x <= 60:  # Ideal range for calendar spreads
                mc_score = 15.0
                factors.append(('Optimal Movement Probability', mc_score))
            elif 30 <= prob_1x <= 70:
                mc_score = 8.0
                factors.append(('Good Movement Probability', mc_score))
            else:
                mc_score = -10.0
                factors.append(('Suboptimal Movement Probability', mc_score))
            
            # Earnings timing factor (up to ±10 points)
            if 1 <= days_to_earnings <= 7:
                earnings_score = 10.0
                factors.append(('Optimal Earnings Timing', earnings_score))
            elif 8 <= days_to_earnings <= 14:
                earnings_score = 5.0
                factors.append(('Good Earnings Timing', earnings_score))
            else:
                earnings_score = -5.0
                factors.append(('Suboptimal Earnings Timing', earnings_score))
            
            # Greeks factor (up to ±10 points)
            net_theta = greeks.get('net_theta', 0.0)
            if net_theta > 0:  # Positive theta is good for calendar spreads
                greeks_score = 10.0
                factors.append(('Positive Theta Decay', greeks_score))
            elif net_theta > -5.0:
                greeks_score = 5.0
                factors.append(('Manageable Theta', greeks_score))
            else:
                greeks_score = -5.0
                factors.append(('Negative Theta', greeks_score))
            
            # Calculate final score
            total_adjustment = sum(score for _, score in factors)
            final_score = max(0.0, min(100.0, base_score + total_adjustment))
            
            return ConfidenceScore(
                overall_score=final_score,
                factors=factors,
                recommendation=self._get_recommendation(final_score),
                risk_level=self._get_risk_level(final_score)
            )
            
        except Exception as e:
            self.logger.error(f"Error calculating confidence score for {symbol}: {e}")
            return ConfidenceScore(
                overall_score=50.0,
                factors=[('Calculation Error', 0.0)],
                recommendation="ANALYZE MANUALLY",
                risk_level="UNKNOWN"
            )
    
    def _get_recommendation(self, score: float) -> str:
        """Get trading recommendation based on confidence score"""
        if score >= 75:
            return "STRONG BUY"
        elif score >= 65:
            return "BUY"
        elif score >= 55:
            return "CONSIDER"
        elif score >= 45:
            return "WEAK"
        else:
            return "AVOID"
    
    def _get_risk_level(self, score: float) -> str:
        """Get risk level based on confidence score"""
        if score >= 70:
            return "LOW"
        elif score >= 55:
            return "MODERATE"
        elif score >= 40:
            return "HIGH"
        else:
            return "VERY HIGH"
    
    def _prepare_ml_features(self, symbol: str, current_price: float,
                           volatility_metrics: dict, days_to_earnings: int,
                           options_data: dict) -> dict:
        """Prepare features for ML prediction"""
        return {
            'iv_rv_ratio': volatility_metrics.get('iv_rv_ratio', 1.0),
            'term_structure_slope': volatility_metrics.get('term_structure_slope', 0.0),
            'days_to_earnings': days_to_earnings,
            'vix_level': volatility_metrics.get('vix', 20.0),
            'volume_ratio': options_data.get('volume_ratio', 1.0),
            'open_interest_ratio': options_data.get('oi_ratio', 1.0),
            'iv_rank': volatility_metrics.get('iv_rank', 0.5),
            'iv_percentile': volatility_metrics.get('iv_percentile', 50.0),
            'gamma_level': options_data.get('gamma_exposure', 0.01),
            'delta_skew': options_data.get('delta_skew', 0.0)
        }
    
    def _calculate_risk_metrics(self, current_price: float, options_data: dict,
                              contracts: int, debit_override: Optional[float],
                              volatility_metrics: dict) -> RiskMetrics:
        """Calculate comprehensive risk metrics"""
        try:
            # Calculate debit
            if debit_override:
                debit = debit_override
            else:
                # Estimate debit from options data
                short_premium = options_data.get('short_premium', current_price * 0.02)
                long_premium = options_data.get('long_premium', current_price * 0.025)
                debit = long_premium - short_premium
            
            # Maximum loss (debit paid)
            max_loss_per_contract = debit
            max_loss_total = max_loss_per_contract * contracts * 100
            
            # Maximum profit (estimated at 50% of debit)
            max_profit_per_contract = debit * 0.5
            max_profit_total = max_profit_per_contract * contracts * 100
            
            # Break-even points
            strike = options_data.get('strike', current_price)
            break_even_upper = strike + debit
            break_even_lower = strike - debit
            
            # Probability of profit (from Monte Carlo if available)
            prob_profit = options_data.get('prob_profit', 0.5)
            
            # Risk-reward ratio
            risk_reward_ratio = max_profit_per_contract / max_loss_per_contract if max_loss_per_contract > 0 else 0
            
            # Expected value calculation
            expected_value = (prob_profit * max_profit_per_contract - 
                            (1 - prob_profit) * max_loss_per_contract)
            
            return RiskMetrics(
                max_loss_per_contract=max_loss_per_contract,
                max_loss_total=max_loss_total,
                max_profit_per_contract=max_profit_per_contract,
                max_profit_total=max_profit_total,
                break_even_upper=break_even_upper,
                break_even_lower=break_even_lower,
                probability_of_profit=prob_profit,
                risk_reward_ratio=risk_reward_ratio,
                expected_value=expected_value,
                debit_paid=debit,
                contracts=contracts
            )
            
        except Exception as e:
            self.logger.error(f"Error calculating risk metrics: {e}")
            return RiskMetrics(
                max_loss_per_contract=0.0,
                max_loss_total=0.0,
                max_profit_per_contract=0.0,
                max_profit_total=0.0,
                break_even_upper=current_price,
                break_even_lower=current_price,
                probability_of_profit=0.5,
                risk_reward_ratio=0.0,
                expected_value=0.0,
                debit_paid=0.0,
                contracts=contracts
            )
    
    def _on_analysis_complete(self, request_id: str, result: AnalysisResult):
        """Handle analysis completion"""
        try:
            if request_id in self.active_analyses:
                request = self.active_analyses.pop(request_id)
                
                # Cache the result
                cache_key = self._get_cache_key(request)
                self.analysis_cache[cache_key] = result
                
                # Emit completion signal
                self.analysis_completed.emit(request.symbol, result)
                
                self.logger.info(f"Analysis completed for {request.symbol}")
            
        except Exception as e:
            self.logger.error(f"Error handling analysis completion: {e}")
    
    def _on_analysis_error(self, request_id: str, error: Exception):
        """Handle analysis error"""
        try:
            if request_id in self.active_analyses:
                request = self.active_analyses.pop(request_id)
                
                # Emit error signal
                self.analysis_error.emit(request.symbol, str(error))
                
                self.logger.error(f"Analysis failed for {request.symbol}: {error}")
            
        except Exception as e:
            self.logger.error(f"Error handling analysis error: {e}")
    
    def _cleanup_cache(self):
        """Clean up old cache entries"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=1)
            
            old_keys = [
                key for key, result in self.analysis_cache.items()
                if result.timestamp < cutoff_time
            ]
            
            for key in old_keys:
                del self.analysis_cache[key]
            
            if old_keys:
                self.logger.debug(f"Cleaned up {len(old_keys)} old cache entries")
                
        except Exception as e:
            self.logger.error(f"Error cleaning up cache: {e}")
    
    def clear_cache(self):
        """Clear all cached results"""
        self.analysis_cache.clear()
        self.logger.info("Analysis cache cleared")
    
    def get_cached_result(self, symbol: str, parameters: dict = None) -> Optional[AnalysisResult]:
        """Get cached result if available"""
        try:
            # Create a dummy request to generate cache key
            dummy_request = AnalysisRequest(
                symbol=symbol,
                parameters=parameters or {}
            )
            cache_key = self._get_cache_key(dummy_request)
            
            if cache_key in self.analysis_cache:
                result = self.analysis_cache[cache_key]
                
                # Check if still valid (15 minutes)
                if (datetime.now() - result.timestamp).total_seconds() < 900:
                    return result
                else:
                    # Remove expired cache entry
                    del self.analysis_cache[cache_key]
            
            return None
            
        except Exception as e:
            self.logger.error(f"Error getting cached result: {e}")
            return None